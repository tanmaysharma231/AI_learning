{"cells":[{"source":"# Prompt Engineering with GPT and LangChain","metadata":{},"id":"a6d014ee-e3b7-409c-948b-ac0152f49563","cell_type":"markdown"},{"source":"LangChain is framework that is extremely helpful for prompt engineering and the integration of generative AI capabilities in applications or data platforms. It has many capabilities, some of which will not be introduced until later modules, but we will start with a gentle introduction to some of the easy-to-understand concepts in the framework.\n\nYou'll build an AI agent that uses Python and GPT to perform sentiment analysis on financial headlines.\n\nIn more detail, you'll cover:\n- Getting set up with an OpenAI developer account and integration with Workspace.\n- Interacting with OpenAI models through the langchain framework.\n- Using prompt templates that write reusable, dynamic prompts.\n- Working with LLM chains.\n- Automatically parsing the output of an LLM to be used downstream.\n- Working with langchain agents and tools.\n- Using the OpenAI Moderation API to filter explicit content.\n\nFor this project, we are using two small samples: `financial_headlines.txt` and `reddit_comments.txt`. These 5-6 line samples are kept short to keep evaluation easy, but keep in mind that this same code and prompt engineering techniques can scale to datasets of much larger size.","metadata":{},"id":"9a610d9c-089e-4b41-803d-17024f68c51a","cell_type":"markdown"},{"source":"### Maintenance note, May 2024\n\nSince this code-along was released, the Python packages for working with the OpenAI API have changed their syntax. The instructions, hints, and code have been updated to use the latest syntax, but the video has not been updated. Consequently, it is now slightly out of sync. Trust the workbook, not the video.","metadata":{},"id":"5aa7c593-da16-4b0a-9cb0-0b3e3a5ec8ae","cell_type":"markdown"},{"source":"### Before you begin","metadata":{},"id":"9358e4e8-7bba-4f77-a4c1-80a49c57869e","cell_type":"markdown"},{"source":"You'll need a developer account with OpenAI.\n\nSee getting-started.ipynb for steps on how to create an API key and store it in Workspace. In particular, you'll need to follow the instructions in the \"Getting started with OpenAI\" and \"Setting up Workspace Integrations\" sections.","metadata":{},"id":"51a7c002-1011-401e-b7f1-c8f92cee40a8","cell_type":"markdown"},{"source":"## Task 0: Setup","metadata":{},"id":"833b24bb-221d-4d34-9927-8b83496fb65d","cell_type":"markdown"},{"source":"We need to install a few packages, one of which being the `langchain` package. This is currently being developed quickly, sometimes with breaking changes, so we fix the version.\n\n`langchain` depends on a recent version of `typing_extensions`, so we need to update that package, again fixing the version.","metadata":{},"id":"2c4850c8-97f7-4389-96c6-9f44ecbfd06d","cell_type":"markdown"},{"source":"### Instructions\n\nRun the following code to install `openai`, `langchain`, `typing_extensions` and `pandas`.","metadata":{},"id":"115b1f8e-55a2-471e-8c45-0eaf3e685a44","cell_type":"markdown"},{"source":"# Install openai.\n!pip install openai==0.28.0","metadata":{"executionCancelledAt":null,"executionTime":3373,"lastExecutedAt":1747335971554,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Install openai.\n!pip install openai==0.28.0","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"4de2a21d-1d16-4bef-b401-64760a2b9735","cell_type":"code","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting openai==0.28.0\n  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (4.67.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (3.11.12)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (2025.1.31)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.18.3)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28.0) (4.12.2)\nDownloading openai-0.28.0-py3-none-any.whl (76 kB)\nInstalling collected packages: openai\n\u001b[33m  WARNING: The script openai is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncrewai 0.30.11 requires openai<2.0.0,>=1.13.3, but you have openai 0.28.0 which is incompatible.\nembedchain 0.1.113 requires openai>=1.1.1, but you have openai 0.28.0 which is incompatible.\ninstructor 0.5.2 requires openai<2.0.0,>=1.1.0, but you have openai 0.28.0 which is incompatible.\nlangchain-openai 0.1.7 requires openai<2.0.0,>=1.24.0, but you have openai 0.28.0 which is incompatible.\npyautogen 0.2.29 requires openai>=1.3, but you have openai 0.28.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed openai-0.28.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"}]},{"source":"# Install langchain.\n!pip install langchain==0.0.293","metadata":{"executionCancelledAt":null,"executionTime":4897,"lastExecutedAt":1747335976453,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Install langchain.\n!pip install langchain==0.0.293","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"64096b2a-d970-4045-8fd1-883f0bb61b4b","cell_type":"code","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting langchain==0.0.293\n  Downloading langchain-0.0.293-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.293) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.293) (2.0.38)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.293) (3.11.12)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.293) (4.0.3)\nCollecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.293)\n  Downloading dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\nCollecting langsmith<0.1.0,>=0.0.38 (from langchain==0.0.293)\n  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.293) (2.10.2)\nRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.293) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.293) (2.7.1)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.293) (2.32.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.293) (8.5.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.293) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.293) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.293) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.293) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.293) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.293) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.293) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.293) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.293) (0.9.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.293) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.293) (2.18.2)\nRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.293) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.293) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.293) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.293) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.293) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.293) (3.1.1)\nRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.293) (23.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.293) (1.0.0)\nDownloading langchain-0.0.293-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\nDownloading langsmith-0.0.92-py3-none-any.whl (56 kB)\nInstalling collected packages: dataclasses-json, langsmith, langchain\n\u001b[33m  WARNING: The script langsmith is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncrewai 0.30.11 requires langchain<0.2.0,>=0.1.10, but you have langchain 0.0.293 which is incompatible.\ncrewai 0.30.11 requires openai<2.0.0,>=1.13.3, but you have openai 0.28.0 which is incompatible.\nembedchain 0.1.113 requires langchain<0.2.0,>=0.1.4, but you have langchain 0.0.293 which is incompatible.\nembedchain 0.1.113 requires openai>=1.1.1, but you have openai 0.28.0 which is incompatible.\nlangchain-community 0.0.38 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.0.92 which is incompatible.\nlangchain-core 0.1.53 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.0.92 which is incompatible.\nlangchain-openai 0.1.7 requires openai<2.0.0,>=1.24.0, but you have openai 0.28.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed dataclasses-json-0.5.14 langchain-0.0.293 langsmith-0.0.92\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"}]},{"source":"# Install typing-extensions.\n!pip install typing-extensions==4.8.0","metadata":{"executionCancelledAt":null,"executionTime":3047,"lastExecutedAt":1747335979502,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Install typing-extensions.\n!pip install typing-extensions==4.8.0","outputsMetadata":{"0":{"height":311,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"93009418-4306-4645-ae65-184741201267","cell_type":"code","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting typing-extensions==4.8.0\n  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\nDownloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\nInstalling collected packages: typing-extensions\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naltair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.8.0 which is incompatible.\nembedchain 0.1.113 requires langchain<0.2.0,>=0.1.4, but you have langchain 0.0.293 which is incompatible.\nembedchain 0.1.113 requires openai>=1.1.1, but you have openai 0.28.0 which is incompatible.\nlangchain-community 0.0.38 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.0.92 which is incompatible.\ntypeguard 4.4.1 requires typing-extensions>=4.10.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed typing-extensions-4.8.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"}]},{"source":"# Install the openai package, locked to version 1.27\n!pip install openai==1.27\n\n# Install the langchain package, locked to version 0.1.19\n!pip install langchain==0.1.19\n\n# Install the langchain-openai package, locked to version 0.1.6\n!pip install langchain-openai==0.1.6\n\n# Install the langchain-experimental package, locked to version 0.0.58\n!pip install langchain-experimental==0.0.58\n\n# Update the typing_extensions package, locked to version 4.11.0\n!pip install typing_extensions==4.11.0","metadata":{"executionCancelledAt":null,"executionTime":17795,"lastExecutedAt":1747335997298,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Install the openai package, locked to version 1.27\n!pip install openai==1.27\n\n# Install the langchain package, locked to version 0.1.19\n!pip install langchain==0.1.19\n\n# Install the langchain-openai package, locked to version 0.1.6\n!pip install langchain-openai==0.1.6\n\n# Install the langchain-experimental package, locked to version 0.0.58\n!pip install langchain-experimental==0.0.58\n\n# Update the typing_extensions package, locked to version 4.11.0\n!pip install typing_extensions==4.11.0","outputsMetadata":{"0":{"height":616,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"debdfbd2-2062-4103-a518-0c69a595aca9","outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting openai==1.27\n  Downloading openai-1.27.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (4.8.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.27) (1.7.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (0.27.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (2.7.1)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /home/repl/.local/lib/python3.10/site-packages (from openai==1.27) (4.8.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.27) (1.2.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.27) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.27) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.27) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.27) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.27) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.27) (2.18.2)\nDownloading openai-1.27.0-py3-none-any.whl (314 kB)\nInstalling collected packages: openai\n  Attempting uninstall: openai\n    Found existing installation: openai 0.28.0\n    Uninstalling openai-0.28.0:\n      Successfully uninstalled openai-0.28.0\n\u001b[33m  WARNING: The script openai is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncrewai 0.30.11 requires langchain<0.2.0,>=0.1.10, but you have langchain 0.0.293 which is incompatible.\nembedchain 0.1.113 requires langchain<0.2.0,>=0.1.4, but you have langchain 0.0.293 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed openai-1.27.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nCollecting langchain==0.1.19\n  Downloading langchain-0.1.19-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.0.38)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (3.11.12)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/repl/.local/lib/python3.10/site-packages (from langchain==0.1.19) (0.5.14)\nRequirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (0.0.38)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (0.1.53)\nRequirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (0.0.2)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.19)\n  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.7.1)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.32.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (8.5.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19) (0.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19) (1.33)\nRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19) (23.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (0.27.2)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (1.0.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (2.18.2)\nRequirement already satisfied: typing-extensions>=4.6.1 in /home/repl/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.1.19) (4.8.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.19) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (4.8.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (1.0.7)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain==0.1.19) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.19) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (1.2.2)\nDownloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\nInstalling collected packages: langsmith, langchain\n  Attempting uninstall: langsmith\n    Found existing installation: langsmith 0.0.92\n    Uninstalling langsmith-0.0.92:\n      Successfully uninstalled langsmith-0.0.92\n\u001b[33m  WARNING: The script langsmith is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0m  Attempting uninstall: langchain\n    Found existing installation: langchain 0.0.293\n    Uninstalling langchain-0.0.293:\n      Successfully uninstalled langchain-0.0.293\n\u001b[33m  WARNING: The script langchain-server is installed in '/home/repl/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0mSuccessfully installed langchain-0.1.19 langsmith-0.1.147\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nCollecting langchain-openai==0.1.6\n  Downloading langchain_openai-0.1.6-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.6) (0.1.53)\nRequirement already satisfied: openai<2.0.0,>=1.24.0 in /home/repl/.local/lib/python3.10/site-packages (from langchain-openai==0.1.6) (1.27.0)\nRequirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.6) (0.7.0)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (6.0.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.0 in /home/repl/.local/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (0.1.147)\nRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (23.2)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (2.7.1)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (8.5.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (4.8.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.7.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (0.27.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /home/repl/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (4.8.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (2.32.3)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.2.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (1.0.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (2.18.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (2.3.0)\nDownloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\nInstalling collected packages: langchain-openai\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nembedchain 0.1.113 requires langchain-openai<0.2.0,>=0.1.7, but you have langchain-openai 0.1.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-openai-0.1.6\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nCollecting langchain-experimental==0.0.58\n  Downloading langchain_experimental-0.0.58-py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: langchain<0.2.0,>=0.1.17 in /home/repl/.local/lib/python3.10/site-packages (from langchain-experimental==0.0.58) (0.1.19)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain-experimental==0.0.58) (0.1.53)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.0.38)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.11.12)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/repl/.local/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.5.14)\nRequirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.0.38)\nRequirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.0.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/repl/.local/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.1.147)\nRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.7.1)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.32.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain-experimental==0.0.58) (1.33)\nRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain-experimental==0.0.58) (23.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain-experimental==0.0.58) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.27.2)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.0.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.18.2)\nRequirement already satisfied: typing-extensions>=4.6.1 in /home/repl/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (4.8.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (4.8.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.0.7)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.14.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.2.2)\nDownloading langchain_experimental-0.0.58-py3-none-any.whl (199 kB)\nInstalling collected packages: langchain-experimental\nSuccessfully installed langchain-experimental-0.0.58\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nCollecting typing_extensions==4.11.0\n  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\nDownloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\nInstalling collected packages: typing_extensions\n  Attempting uninstall: typing_extensions\n    Found existing installation: typing_extensions 4.8.0\n    Uninstalling typing_extensions-4.8.0:\n      Successfully uninstalled typing_extensions-4.8.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nembedchain 0.1.113 requires langchain-openai<0.2.0,>=0.1.7, but you have langchain-openai 0.1.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed typing_extensions-4.11.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"}],"execution_count":4},{"source":"# Install pandas.\n!pip install pandas==2.0.3","metadata":{"executionCancelledAt":null,"executionTime":6879,"lastExecutedAt":1747336004179,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Install pandas.\n!pip install pandas==2.0.3","outputsMetadata":{"0":{"height":395,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"b00a5793-03ab-4176-9843-eeaaf224dbb7","cell_type":"code","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting pandas==2.0.3\n  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2025.1)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2025.1)\nRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (1.26.4)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.3) (1.16.0)\nDownloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m138.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pandas\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nmizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\nplotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\nxarray 2025.1.2 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pandas-2.0.3\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"}]},{"source":"For this project, we need first need to load the openai and os packages to set the API key from the environment variables you just created.","metadata":{},"id":"be271ab6-b977-45b3-8b5d-f86b73e9fd2b","cell_type":"markdown"},{"source":"### Instructions\n\n- Import the `os` package.\n- Import the `openai` package.\n- Set `openai.api_key` to the `OPENAI_API_KEY` environment variable.","metadata":{},"id":"30c2c737-4fd2-4a6a-b9c0-710118699d86","cell_type":"markdown"},{"source":"# Import the os package.\nimport os \n\n# Import the openai package.\n\nimport openai\n# Set openai.api_key to the OPENAI_API_KEY environment variable.\nopen.api_key=os.environ[\"OPENAI_API_KEY\"]","metadata":{"executionCancelledAt":null,"executionTime":2087,"lastExecutedAt":1747336006267,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the os package.\nimport os \n\n# Import the openai package.\n\nimport openai\n# Set openai.api_key to the OPENAI_API_KEY environment variable.\nopen.api_key=os.environ[\"OPENAI_API_KEY\"]"},"id":"2d301524-67c0-4894-8e2a-72787de3c9bc","cell_type":"code","execution_count":6,"outputs":[]},{"source":"For the `langchain` package, let's start by importing it's `OpenAI` and `ChatOpenAI` class, which are used to interact with completion models and chat completion models respectively.\n\nCompletion models, such as the GPT-1, GPT-2, GPT-3 and GPT-3.5, work as an advanced autocomplete model. Given a certain snippet of text as input, they will complete the text until a certain point. This could be either an end-of-sequence token (a natural way of stopping), the model reaching its maximum token limit for outputs and so on.\n\nChat completion models, such as GPT-3.5-Turbo (the ChatGPT model) and GPT-4, are designed for conversational use. These models are typically more fine-tuned for conversations, keep a prompt/conversation history and allow access to a system message, which we can use as a meta prompt to define a role, a tone of voice, a scope, etc.\n\nCompletion models and chat completion models tend to work with different classes and functions in the SDK. For that reason, we will start by importing both classes.","metadata":{},"id":"8fa361c0-da75-42f5-84c7-142ed2307c20","cell_type":"markdown"},{"source":"### Instructions\n\n- Import `OpenAI` and `ChatOpenAI` from `langchain_openai`.\n- From the `langchain.prompts` module, import the `PromptTemplate` and `ChatPromptTemplate` classes.\n- From the `langchain.output_parsers` module, import the `CommaSeparatedListOutputParser` class.\n- From the `langchain_experimental.agents.agent_toolkits` module, import `create_python_agent`.\n- From the `langchain_experimental.tools.python.tool` module, import `PythonREPLTool`.","metadata":{},"id":"f18c0e9a-dcc2-4862-895b-e6ecb4347e5f","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n    \nRemember the syntax for Python imports: `from ... import ...`\n\n</p>\n</details>","metadata":{},"id":"b0e7d533-4a77-4c17-a9c2-22b4a76b458f","cell_type":"markdown"},{"source":"# From langchain_openai, import OpenAI, ChatOpenAI\nfrom langchain_openai import OpenAI, ChatOpenAI\n\n# From langchain.prompts, import PromptTemplate, ChatPromptTemplate\nfrom langchain.prompts import PromptTemplate, ChatPromptTemplate\n\n# From langchain.output_parsers, import CommaSeparatedListOutputParser\nfrom langchain.output_parsers import CommaSeparatedListOutputParser\n\n# From langchain_experimental.agents.agent_toolkits, import create_python_agent\nfrom langchain_experimental.agents.agent_toolkits import create_python_agent\n\n# From langchain_experimental.tools.python.tool, import PythonREPLTool\nfrom langchain_experimental.tools.python.tool import PythonREPLTool\n\n","metadata":{"executionCancelledAt":null,"executionTime":860,"lastExecutedAt":1747336007129,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# From langchain_openai, import OpenAI, ChatOpenAI\nfrom langchain_openai import OpenAI, ChatOpenAI\n\n# From langchain.prompts, import PromptTemplate, ChatPromptTemplate\nfrom langchain.prompts import PromptTemplate, ChatPromptTemplate\n\n# From langchain.output_parsers, import CommaSeparatedListOutputParser\nfrom langchain.output_parsers import CommaSeparatedListOutputParser\n\n# From langchain_experimental.agents.agent_toolkits, import create_python_agent\nfrom langchain_experimental.agents.agent_toolkits import create_python_agent\n\n# From langchain_experimental.tools.python.tool, import PythonREPLTool\nfrom langchain_experimental.tools.python.tool import PythonREPLTool\n\n"},"id":"e08d7737-e753-4e54-9ae4-b65e365bf36f","cell_type":"code","execution_count":7,"outputs":[]},{"source":"## Task 1: Import the Financial News Headlines Data","metadata":{},"id":"303fc31e-5f83-41a3-a078-e929a11e8bf0","cell_type":"markdown"},{"source":"A small sample of financial headlines is stored in `financial_headlines.txt`.\n\nOur first step is to read in the text file and store the headlines in a Python list.","metadata":{},"id":"b1c1b04e-0de7-4050-950e-4f64dfc6a58d","cell_type":"markdown"},{"source":"### Instructions\n\nImport the text file to a Python list.\n\n- Open `financial_headlines.txt` for reading.\n- Read in the lines using the `.readlines()` method. Assign to `headlines`.\n- Print the sample headlines.","metadata":{},"id":"10678d41-3b1c-4471-9e4c-9b1f32ea038f","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\n- A good way of opening (and automatically closing) a file is using: `with open(file_name, \"r\") as file:`.\n- We can then use the `.readlines()` method on the `file` variable.\n    \n</p>\n</details>","metadata":{},"id":"6afdccc3-7743-4a14-9d98-8aa3b32166be","cell_type":"markdown"},{"source":"# Open the text file and read its lines.\nwith open(\"financial_headlines.txt\",\"r\") as data:\n    headlines=data.readlines()\n\n# Print all headlines.\nprint(headlines)","metadata":{"executionCancelledAt":null,"executionTime":110,"lastExecutedAt":1747336007241,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Open the text file and read its lines.\nwith open(\"financial_headlines.txt\",\"r\") as data:\n    headlines=data.readlines()\n\n# Print all headlines.\nprint(headlines)","outputsMetadata":{"0":{"height":248,"type":"stream"}}},"id":"1b5638c5-9db0-4731-8170-e7b6c1a99697","cell_type":"code","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":"[\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\\n\", 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\\n', 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\\n', 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\\n', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\\n\", 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']\n"}]},{"source":"The headlines seem to a bit of whitespace preceding the punctuation, but this does not influence the performance of our large language model.\nYou can also see that every headline ends with a new line (`\\n`).\n\nWe can quickly strip the `\\n` from the end of each headline, as this might improve visibility later down the line, when printing these headlines in a dataframe. ","metadata":{},"id":"7c0a4789-58a1-4546-bb39-c5b540eb8559","cell_type":"markdown"},{"source":"### Instructions\n\nStrip the `\\n` character from the end of every news headline.\n\n- Loop through `headlines` and use the `.strip()` method to remove the `\\n` character from each line.\n- Print the result.","metadata":{},"id":"5c7b522e-32b6-4818-9834-f0c2bbf7f230","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\nTo quickly reassign the adjusted elements of our list, we can make use of Python list comprehensions.\n    \nFor example: `new_list = [f(x) for x in list]`\n\n</p>\n</details>","metadata":{},"id":"06c8394a-0d77-4d68-a20a-06c1701a8370","cell_type":"markdown"},{"source":"# Strip the new line character from all headlines.\nheadlines=[line.strip(\"\\n\") for line in headlines]\n\n# Print all headlines.\nheadlines","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1747336007290,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Strip the new line character from all headlines.\nheadlines=[line.strip(\"\\n\") for line in headlines]\n\n# Print all headlines.\nheadlines"},"id":"980f8d06-4d48-4fb9-9cab-ac66a8371910","cell_type":"code","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":"[\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\",\n 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .',\n 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .',\n 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .',\n \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\",\n 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']"},"metadata":{},"execution_count":9}]},{"source":"## Task 2: Setting up Prompt Templates","metadata":{},"id":"f389f489-eddd-45c0-84d7-44dd8f9ca5b3","cell_type":"markdown"},{"source":"During this code-along we are using the OpenAI API to programmatically make requests to a GPT-model. This allows us to automate calls to the model, as would be the case when implementing generative AI functionalities in an application or data transformation process.\n\nIn general, when developing an application, we want our code to be modular, scalable and reusable. How do we this with LLM prompts?\n\nThis is where Prompt Templates come into play! It allows for dynamic prompts, with built-in verification tools on whether all inputs are given (this will ease the load on testing). They can easily be saved, versioned and integrated into the code base of an application.\n\nWe will set up Prompt Templates (from the `langchain` package) to automatically determine financial sentiment from the headlines and extract relevant company names. ","metadata":{},"id":"f9f0adf8-630d-4738-95a2-9a8abc0edd67","cell_type":"markdown"},{"source":"### Usage of Prompt Templates\n\nA prompt template can have dynamic input, which can be added using `{ }`.\n\nExample: `\"Can you give me some suggestions for my trip to {city}?\"`\n\nWe can then format the prompt template by filling in the `city` variable.\n\nCertain prompts that are often reused programmatically in application processes might be very lengthy and can be carefully designed to meet a specific need. For example, if we want the output of a sentiment analysis by the GPT-model to be limited to either positive, negative or neutral (without anything else in the answer), we need to explicitly tell the model within our prompt. In order to not accidentally forget this in any of the future prompts, it is best practice to design and save a prompt template.","metadata":{},"id":"ddb5a5e6-e828-4af4-afb4-767dd2ab798b","cell_type":"markdown"},{"source":"### Types of Prompt Templates\n\nPrompt Templates in Langchain come in two formats:\n- PromptTemplate: this is used for completion models.\n- ChatPromptTemplate: this is used for chat completion models. On top of the normal input prompt, these can hold a system message (meta prompt) and a conversation history.\n\nLet's start by creating a PromptTemplate and ChatPromptTemplate.","metadata":{},"id":"b52a25d6-0bc4-487b-812e-19895b80ea9c","cell_type":"markdown"},{"source":"### Instructions\n\n- Create a Prompt Template to analyze financial sentiment.\n- Create a `PromptTemplate` object by using its `.from_template()` method. Assign to `prompt_template`.\n- For the template argument, use:\n\n```\n\"Analyze the following financial headline for sentiment: {headline}\"\n```\n\n- Format the prompt using its `.format()` method. Let's use our first headline as input. Assign to `formatted_prompt`.\n- Print the formatted prompt.","metadata":{},"id":"82de02d9-6a87-4ea1-9b56-c3f03b463748","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\n`prompt_template.format()` will have one argument called `headline` (as defined in our `PromptTemplate`), where we pass along the first element of our `headlines` list.\n\n</p>\n</details>","metadata":{},"id":"f2cde322-6970-43ef-a916-0af0d8bd47be","cell_type":"markdown"},{"source":"# Create a dynamic template to analyze a single headline.\nprompt_template=PromptTemplate.from_template(\"Analyze the following financial headline for sentiment: {headline}\")\n\n# Format the prompt template on the first headline of the dataset.\nprompt_template.format(headline=headlines[0])\n\n# Print the formatted template.\nprint(prompt_template)","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1747336007338,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a dynamic template to analyze a single headline.\nprompt_template=PromptTemplate.from_template(\"Analyze the following financial headline for sentiment: {headline}\")\n\n# Format the prompt template on the first headline of the dataset.\nprompt_template.format(headline=headlines[0])\n\n# Print the formatted template.\nprint(prompt_template)","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"id":"e5c74f6d-fad2-4a52-a2e4-653768d33c33","cell_type":"code","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"input_variables=['headline'] template='Analyze the following financial headline for sentiment: {headline}'\n"}]},{"source":"Now let's set up a `ChatPromptTemplate`, which are compatible with conversational models like GPT-4 and GPT-3.5-Turbo. When using the ChatPromptTemplate, we have the ability to assign a system message, so let's make use of this.\n\nIn terms of prompt engineering, what we write in the system can heavily influence the quality of the output. Some things we can do using the system message is:\n- Define a role: *\"You are a X\", \"Your role is to do X\", ...*\n- Define a tone of voice: *\"Respond in a formal manner\", \"Use customer-oriented language\", ...*\n- Define restrictions on output format: *\"The format of the output is X\", \"The output is strictly limited to X, Y, Z\", ...*\n- Define a scope: *\"Only answer questions on topic X\", \"If the user questions is not about X, answer with Y\", ...*\n\nYou will notice some of these tricks applied to the following system message.","metadata":{},"id":"d858c71f-a8eb-4115-a747-7bd643595ea5","cell_type":"markdown"},{"source":"### Instructions\n\n- Define a system message as follows and assign to `system_message`.\n\n```\n\"\"\"You are performing sentiment analysis on news headlines regarding financial analysis. \nThis sentiment is to be used to advice financial analysts. \nThe format of the output has to be consistent. \nThe output is strictly limited to any of the following options: [positive, negative, neutral].\"\"\"\n```\n\n- Instantiate a new `ChatPromptTemplate` using its `.from_messages()` method. Assign to `chat_template`.\n    - This method will take a list of tuples as input. We need two tuples, one for the system message and one for the human message. To distinguish the two, the first element of the tuple is either `\"system\"` or `\"human\"`.\n    - The second element of the tuple is the actual message, as string. For the system message, you can use the `system_message`variable. For the human message, we can reuse the same message as before (including the input variable `{headlines}`).\n    \n- Format the template using its `.format_messages()` method. Let's use our first headline again. Assign to `formatted_chat_template`.\n- Print the formatted template.","metadata":{},"id":"054ac0a5-48d9-46a8-bc27-412280ea0eee","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\nThe input for `ChatPromptTemplate.from_messages()` follows this structure:\n`[(\"system\", system_message), (\"human\", input_prompt)]`\n\n</p>\n</details>","metadata":{},"id":"8636ebd3-e8f2-4b47-b962-bc921e0bced7","cell_type":"markdown"},{"source":"# Define the system message.\nsystem_message=\"\"\"You are performing sentiment analysis on news headlines regarding financial analysis. \nThis sentiment is to be used to advice financial analysts. \nThe format of the output has to be consistent. \nThe output is strictly limited to any of the following options: [positive, negative, neutral].\"\"\"\n\n# Initialize a new ChatPromptTemplate with a system message and human message.\nchat_template=ChatPromptTemplate.from_messages([(\"system\",system_message),(\"human\", \"Analyze the following financial headline for sentiment: {headline}\")])\n\n# Format the ChatPromptTemplate.\nformat_temp=chat_template.format_messages(headline=headlines[0])\n\n# Print the formatted template.\nformat_temp","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1747336007390,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the system message.\nsystem_message=\"\"\"You are performing sentiment analysis on news headlines regarding financial analysis. \nThis sentiment is to be used to advice financial analysts. \nThe format of the output has to be consistent. \nThe output is strictly limited to any of the following options: [positive, negative, neutral].\"\"\"\n\n# Initialize a new ChatPromptTemplate with a system message and human message.\nchat_template=ChatPromptTemplate.from_messages([(\"system\",system_message),(\"human\", \"Analyze the following financial headline for sentiment: {headline}\")])\n\n# Format the ChatPromptTemplate.\nformat_temp=chat_template.format_messages(headline=headlines[0])\n\n# Print the formatted template.\nformat_temp"},"id":"2d621445-3804-442d-8040-8405c6c9c83f","cell_type":"code","execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":"[SystemMessage(content='You are performing sentiment analysis on news headlines regarding financial analysis. \\nThis sentiment is to be used to advice financial analysts. \\nThe format of the output has to be consistent. \\nThe output is strictly limited to any of the following options: [positive, negative, neutral].'),\n HumanMessage(content=\"Analyze the following financial headline for sentiment: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\")]"},"metadata":{},"execution_count":11}]},{"source":"## Task 3: Setting up LLM Chains","metadata":{},"id":"ec62e063-c2bf-42c9-bb54-f774e3f13ff2","cell_type":"markdown"},{"source":"We will briefly cover the concept of chains in langchain. LLM Chains are an easy way to combine a model with a prompt template. These chains can be created for both *completion models* and *chat completion models*.\n\nLLM Chains can be used to \"chain\" prompt flows, by using the output of a previous chain as input for the next.\n\nLet's set up a chain for a completion model first, using the templates that we've just built.","metadata":{},"id":"907abbe1-0ecb-4b33-8a46-8471c214df38","cell_type":"markdown"},{"source":"### Instructions\n\nCreate an LLM chain for a completion model.\n- Define an `OpenAI()` client model. Assign to `client`.\n- Pipe the prompt template to the client. Assign to `completion_chain`.\n- Invoke `completion_chain`, setting the headline variable to the first element of the `headlines` list.","metadata":{},"id":"a597b3fb-9710-4054-a0cc-a0541cfb3f4a","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\nTo create an LLM chain, you pipe the template to the client model.\n    \n```py\nchain = prompt | client\n```\n\n---\n\nTo pass the prompt to GPT and get a response, you invoke the chain with `.invoke()`. This takes a dictionary argument containing the  names and values of the variables you want to pass into the template.\n    \n```py\nchain.invoke({\"key\": value})\n```\n\n</p>\n</details>","metadata":{},"id":"f2de43f2-64c1-4985-a4d1-0306a5159c07","cell_type":"markdown"},{"source":"# Define a client model. Assign to client.\nclient= OpenAI()\n\n# Pipe the prompt template to the client. Assign to completion_chain.\ncomplete_chain= prompt_template | client \n\n# Invoke completion_chain, setting the headline variable to the first headline\ncomplete_chain.invoke({\"headline\":headlines[0]})","metadata":{"executionCancelledAt":null,"executionTime":975,"lastExecutedAt":1747336008365,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define a client model. Assign to client.\nclient= OpenAI()\n\n# Pipe the prompt template to the client. Assign to completion_chain.\ncomplete_chain= prompt_template | client \n\n# Invoke completion_chain, setting the headline variable to the first headline\ncomplete_chain.invoke({\"headline\":headlines[0]})"},"id":"234126d2-0e6a-4286-8fd9-2ec95eb5a566","cell_type":"code","execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":"'\\n\\nPositive'"},"metadata":{},"execution_count":12}]},{"source":"Now let's do the same, using a chat completion model.","metadata":{},"id":"20424b97-c01c-4786-9460-beae26fb8a35","cell_type":"markdown"},{"source":"### Instructions\n\n- Define a chat client model. Assign to `chat`.\n- Pipe the chat template to the client. Assign to `chat_chain`.\n- Invoke `chat_chain`, setting the headline to the first element of `headlines`. In the additioanl arguments, set `system_message` to `system_message`.","metadata":{},"id":"e834ad2f-299b-4834-8e05-56eb0b67e99e","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\n`chat_chain.invoke()` takes a dictionary input variable, and the system message can also be passed as a dictionary.\n    \n```py\nchain.invoke(input_dict, {\"system_message\": system_message})\n```\n\n</p>\n</details>","metadata":{},"id":"883ddd72-41e3-426b-b969-74129a1a158d","cell_type":"markdown"},{"source":"# Define a chat client model. Assign to chat.\nclient=ChatOpenAI()\n\n# Pipe the chat template to the client. Assign to chat_chain.\nchat_chain = chat_template | client\n\n# Invoke chat_chain, setting headline to the first headline and using system_message\nchat_chain.invoke({\"headline\":headlines[0]},{\"system_mesage\":system_message})","metadata":{"executionCancelledAt":null,"executionTime":1124,"lastExecutedAt":1747336009490,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define a chat client model. Assign to chat.\nclient=ChatOpenAI()\n\n# Pipe the chat template to the client. Assign to chat_chain.\nchat_chain = chat_template | client\n\n# Invoke chat_chain, setting headline to the first headline and using system_message\nchat_chain.invoke({\"headline\":headlines[0]},{\"system_mesage\":system_message})"},"id":"00a8db2b-fd72-421c-9e17-82a47ee460b5","cell_type":"code","execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":"AIMessage(content='The sentiment of the financial headline is positive.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 115, 'total_tokens': 124, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-437cc86c-8b79-4303-bff6-3ba9e9123f55-0')"},"metadata":{},"execution_count":13}]},{"source":"## Task 4: Extracting Company Names with the Output Parser","metadata":{},"id":"b55de8b3-7e57-4fcb-b160-462b22828122","cell_type":"markdown"},{"source":"Output parsing is a very useful feature in Langchain when integrating LLM outputs into your application. The output parser can automatically transform the output of the GPT-model to numerous data types, such as lists, datetimes, JSONs and so on.\n\nIn this example, we will ask the GPT-model to extract the company name from every headline and instantly assign them to a Python list.\n\nAs we want to combine sentiment with the company name later, we will limit the output to one name per headline.\n\nIn order to format the output as a Python list, we can make use of the `CommaSeparatedListOutputParser` class in Langchain.","metadata":{},"id":"b5c74f27-1a7a-43f8-b0c1-04bfc9611f0f","cell_type":"markdown"},{"source":"### Instructions\n\nCreate an output parser and a formatted prompt template to extract company names from multiple headlines.\n- Instantiate a new `CommaSeparatedListOutputParser` and assign to `output_parser`.\n- To retrieve the parsing instructions from the output parser, we can use its `.get_format_instructions()` method. Assign this to `format_instructions`.\n- Let's instantiate a new `PromptTemplate`. This time we won't use its `.from_template()` method. When calling `PromptTemplate()` with the output parser, we need to pass three arguments:\n    - `template`: here we can use the following string; \n```\n\"List all the company names from the following headlines, limited to one name per headline: {headlines}.\\n{format_instructions}\"\n```\n\n- `input_variables`: This is a list of strings containing the input variables that are required. In our case, this is only `\"headlines\"`.\n- `partial_variables`: Here we pass along a dictionary with the key being `\"format_instructions\"` and the value being the `format_instructions` variable we created earlier.\n- Format the prompt template using the entire `headlines` list.","metadata":{},"id":"60d62a05-8c14-4d02-b6ed-1d896f222724","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\nWe can create a new prompt template using `PromptTemplate(template= , input_variables= , partial_variables= )`\n\n</p>\n</details>","metadata":{},"id":"69682dd4-6bf4-4a4e-a85f-0a6757112956","cell_type":"markdown"},{"source":"# Instantiate the output parser.\noutput_parser = CommaSeparatedListOutputParser()\n\n# Get the format instructions from the output parser.\nformat_instructions = output_parser.get_format_instructions()\n\n# Instantiate a new prompt template with the format instructions.\ncompany_name_prompt = PromptTemplate(template=\"List all the company names from the following headlines, limited to one name per headline: {headlines}.\\n{format_instructions}\", input_variables=[\"headlines\"], partial_variables={\"format_instructions\":format_instructions})\n\n# Format the prompt using all headlines.\ncompany_name_prompt=company_name_prompt.format(headlines=headlines)","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1747336009538,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Instantiate the output parser.\noutput_parser = CommaSeparatedListOutputParser()\n\n# Get the format instructions from the output parser.\nformat_instructions = output_parser.get_format_instructions()\n\n# Instantiate a new prompt template with the format instructions.\ncompany_name_prompt = PromptTemplate(template=\"List all the company names from the following headlines, limited to one name per headline: {headlines}.\\n{format_instructions}\", input_variables=[\"headlines\"], partial_variables={\"format_instructions\":format_instructions})\n\n# Format the prompt using all headlines.\ncompany_name_prompt=company_name_prompt.format(headlines=headlines)"},"id":"6cac36e4-9d98-414e-8204-848c299a3457","cell_type":"code","execution_count":14,"outputs":[]},{"source":"Now that we have a template with format instructions ready, let's send it to a GPT-model and look at the output. We want to run these kinds of tasks with the temperature parameter of the large language model set to zero, as this maximizes precision. \n\nWe tend to distinguish tasks that either require precision or creativity. When we are looking for correctness in the answer (e.g. when generating code) we aim for high precision (by lowering temperature) whereas when generating ideas or content, we might prefer more creativity (by increasing temperature). A simplified explanation of the *temperature* of a large language model is its randomness. When temperature is set to 0, we will get the exact same output, given the same inputs.","metadata":{},"id":"54576b7b-2048-49f6-939c-ced2c8a834d9","cell_type":"markdown"},{"source":"### Instructions\n\nCreate a new Langchain model, send over the template and inspect the parsed output.\n- Instantiate a new `OpenAI()` client model. Set the temperature to 0. Assign to `model`.\n- Invoke `model` on the formatted template. Assign to `_output`. The underscore preceding our variable name indicates that this is just a temporary variable, that will likely be overwritten many times.\n- Use the `.parse()` method of the output parser on the output of the model. Assign to `company_names`.\n- Print the data type of `company_names`.\n- Print the company names.","metadata":{},"id":"e00a6e04-c726-4dc1-a240-9f0b3291de28","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\n- The temperature of the model can be set to 0 by using `OpenAI(temperature= )`.\n- We can get the data type of a variable by using `type(variable)`.\n\n</p>\n</details>","metadata":{},"id":"20ea561c-9b4f-4e6c-a630-eef71d2fc43d","cell_type":"markdown"},{"source":"# Instantiate a Langchain OpenAI Model object.\nmodel=OpenAI(temperature=0)\n\n# Invoke the model on the input.\n_output= model.invoke(company_name_prompt)\n\n# Parse the output.\ncompany_names=output_parser.parse(_output)\n\n# Print the data type the parsed output.\nprint(f\"Data type: {type(company_names)}\\n\")\n\n# Print the output.\nprint(company_names)","metadata":{"executionCancelledAt":null,"executionTime":1170,"lastExecutedAt":1747336010708,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Instantiate a Langchain OpenAI Model object.\nmodel=OpenAI(temperature=0)\n\n# Invoke the model on the input.\n_output= model.invoke(company_name_prompt)\n\n# Parse the output.\ncompany_names=output_parser.parse(_output)\n\n# Print the data type the parsed output.\nprint(f\"Data type: {type(company_names)}\\n\")\n\n# Print the output.\nprint(company_names)","outputsMetadata":{"0":{"height":101,"type":"stream"}}},"id":"f1dde4f8-ccb5-4bf0-a7d6-35f1a1f6e66a","cell_type":"code","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":"Data type: <class 'list'>\n\n['Aktia Group', 'Vaisala Oyj', 'Orion', 'Tiimari', 'Metso Paper', 'Outokumpu Technology']\n"}]},{"source":"## Task 5: Working with Agents and Tools","metadata":{},"id":"f8ab6d2c-87d1-4966-bac0-99f3ba39d195","cell_type":"markdown"},{"source":"Leveraging the agents and tools in LangChain is where the framework's value really starts to shine! But before we dive deeper into this concept, we need to understand MRKL prompts.","metadata":{},"id":"fa5daf04-5793-4fdc-a6d8-268430d7ab17","cell_type":"markdown"},{"source":"### What are MRKL Prompts?\n\nMRKL stands for Modular Reasoning, Knowledge and Language prompts. It is a system composed of a set of modules, often accompanied by an agent that decides how to route prompts to the appropriate module (or tools).\n\nThese kinds of prompts follow a specific format, which we can force the GPT-model to adhere to by using the system message. It will loop through this format (steps 1-5 below) using recursive requests to the GPT-model until we get our final answer. A commonly used format is the following:\n1. Question: the user question (in the first iteration) or follow-up question composed by the GPT-models (in later iterations)\n2. Thought: think about what to do as a next step\n3. Action: pick a tool from the list of tool names we have provided\n4. Action Input: the input for the chosen tool\n5. Observation: the output of the tool","metadata":{},"id":"c8f4e729-a8e9-4d28-bc3f-752cb3efc620","cell_type":"markdown"},{"source":"### What are Tools and Agents?\n\nWe can access (external) tools using the output of the GPT-model. Large language models output only text. In order to call a function (to access a tool) based on the text output of a large language model, we can use agents. They can parse the text output, pick the correct tool and define its input.\n\nThe langchain framework has a wide variety of built-in tools, along with the ability to define additional custom tools. A very common use case for tools is accessing document stores or vector databases to ingest information from our own documents. This will be explored more in-depth in future modules.\n\nFor now, to have a gentle introduction to tools, we have decided on one that does not require external set up (no API token that needs to be created or external database that needs to be set up). \n\nIn this example, we will make use of the `PythonREPLTool`. This allows the GPT-model to run the Python code that it generates, and can be useful for carrying out an abundance of tasks.\n\nNote: as we introduce recursive prompts using agents, it is best practice to always define a maximum number of output tokens. This ensures our costs will not skyrocket if a prompt loop takes too long.","metadata":{},"id":"709a8d80-fb26-4f83-9cf2-19e6cbb00557","cell_type":"markdown"},{"source":"### Instructions\n\nBefore we continue with our financial analysis, let's create a quick example of how code can be ran using a Python agent. In this case, we will ask it to make a calculation (something that most large language models are not trained to do out-of-the-box).\n- Create a Python agent by calling the `create_python_agent()` function. Assign to `agent_executor`. This function takes three arguments:\n    - `llm`: here we can create a new `OpenAI()` model. Let's set the `temperature` to 0 and `max_tokens` to 1000.\n    - `tool`: here we instantiate a new `PythonREPLTool()`.\n    - `verbose`: set this to True so that can we see the prompt loop.\n- Invoke the agent using its `.invoke()` method. As an example, you can ask it: `\"What is the square root of 250? Round the answer down to 4 decimals.\"`","metadata":{},"id":"7234a5ec-0f44-4ca6-9d2e-0a983386b7e7","cell_type":"markdown"},{"source":"\n\n# Instantiate a Python agent, with the PythonREPLTool.\nagent_executor = create_python_agent(\n    llm  = OpenAI(temperature=0, max_tokens=1000),  \n    tool = PythonREPLTool(),\n    verbose = True  # Corrected 'true' to 'True'\n)\n\n# Ask the agent for the solution of a mathematical equation.\nagent_executor.invoke(\"What is the square root of 250? Round the answer down to 4 decimals.\")","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":416,"type":"stream"}}},"id":"9016d465-16b8-48d8-af78-3384a113eaa3","cell_type":"code","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m I can use the math module to calculate the square root.\nAction: Python_REPL\nAction Input: import math\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m Now that the math module is imported, I can use the sqrt function.\nAction: Python_REPL\nAction Input: math.sqrt(250)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m The result is a float, so I can use the round function to round it down to 4 decimals.\nAction: Python_REPL\nAction Input: round(math.sqrt(250), 4)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I now know the final answer.\nFinal Answer: 15.8114\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"},{"output_type":"execute_result","data":{"text/plain":"{'input': 'What is the square root of 250? Round the answer down to 4 decimals.',\n 'output': '15.8114'}"},"metadata":{},"execution_count":16}]},{"source":"Investigate the output above. As we haven't assigned any other tool, the choice of tools for the model was quite limited. Hence under Action, it should list the `Python_REPL` tool.\nThe Action Input will show the actual code that was generated by the GPT-model and executed by the Agent.\n\nNow let's try to use the same agent to help us in our financial news analysis.\n\nWe want to structure our prompt in a clear way, explaining a step by step process. For example:\n- First, *Analyze the sentiment...*\n- Second, *Load this data into a pandas dataframe.*\n- Third, *Save this dataframe to a CSV under the name financial_analysis.csv*\n- ...\n\nLastly, we pass along the headlines (input data) itself.","metadata":{},"id":"867eb98e-bcc4-4278-a562-94e4ff9072b6","cell_type":"markdown"},{"source":"### Instructions\n\nAsk the agent to extract the company name and sentiment from the headlines and save its output in a `.csv` file called `financial_analysis.csv`.\n- Invoke the agent on the following prompt:\n    \n    ``` \n    f\"\"\"For every of the following headlines, extract the company name and whether the financial sentiment is positive, neutral or negative. \n    Load this data into a pandas dataframe. \n    The dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \n    The dataframe can then be saved in the current working directory under the name financial_analysis.csv.\n    If a csv file already exists with the same name, it should be overwritten.\n\n    The headlines are the following:\n    {headlines}\"\"\"\n    ```","metadata":{},"id":"044d23e5-930f-4a11-b3ff-fb42e61222cd","cell_type":"markdown"},{"source":"# Invoke the agent\nprompt_exec=f\"\"\"For every of the following headlines, extract the company name and whether the financial sentiment is positive, neutral or negative. \nLoad this data into a pandas dataframe. \nThe dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \nThe dataframe can then be saved in the current working directory under the name financial_analysis.csv.\nIf a csv file already exists with the same name, it should be overwritten.\n\nThe headlines are the following:\n{headlines}\"\"\"\nagent_executor.invoke(prompt_exec)","metadata":{"executionCancelledAt":null,"executionTime":11452,"lastExecutedAt":1747336028116,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Invoke the agent\nprompt_exec=f\"\"\"For every of the following headlines, extract the company name and whether the financial sentiment is positive, neutral or negative. \nLoad this data into a pandas dataframe. \nThe dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \nThe dataframe can then be saved in the current working directory under the name financial_analysis.csv.\nIf a csv file already exists with the same name, it should be overwritten.\n\nThe headlines are the following:\n{headlines}\"\"\"\nagent_executor.invoke(prompt_exec)","outputsMetadata":{"0":{"height":613,"type":"stream"}}},"id":"d6b142a8-d387-4738-90de-c4d7f7d74fc3","cell_type":"code","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m I need to import the necessary libraries and modules to work with pandas and csv files.\nAction: Python_REPL\nAction Input: import pandas as pd\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to create a list of the headlines.\nAction: Python_REPL\nAction Input: headlines = [\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .', 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .', 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\", 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to create a pandas dataframe with three columns: company name, financial sentiment, and headline.\nAction: Python_REPL\nAction Input: df = pd.DataFrame(columns=['Company Name', 'Financial Sentiment', 'Headline'])\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to extract the company name and financial sentiment from each headline and add it to the dataframe.\nAction: Python_REPL\nAction Input: for headline in headlines:\n    if 'Finnish' in headline:\n        company_name = 'Finnish'\n    else:\n        company_name = 'Unknown'\n    if 'profit' in headline or 'revenues' in headline:\n        financial_sentiment = 'Positive'\n    elif 'loss' in headline:\n        financial_sentiment = 'Negative'\n    else:\n        financial_sentiment = 'Neutral'\n    df = df.append({'Company Name': company_name, 'Financial Sentiment': financial_sentiment, 'Headline': headline}, ignore_index=True)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3mAttributeError(\"'DataFrame' object has no attribute 'append'\")\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to use the pandas .loc method to add rows to the dataframe.\nAction: Python_REPL\nAction Input: for headline in headlines:\n    if 'Finnish' in headline:\n        company_name = 'Finnish'\n    else:\n        company_name = 'Unknown'\n    if 'profit' in headline or 'revenues' in headline:\n        financial_sentiment = 'Positive'\n    elif 'loss' in headline:\n        financial_sentiment = 'Negative'\n    else:\n        financial_sentiment = 'Neutral'\n    df.loc[len(df)] = [company_name, financial_sentiment, headline]\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to save the dataframe as a csv file in the current working directory.\nAction: Python_REPL\nAction Input: df.to_csv('financial_analysis.csv', index=False)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I now know the final answer.\nFinal Answer: The dataframe with the extracted company names, financial sentiment, and headlines has been saved as a csv file in the current working directory under the name financial_analysis.csv.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"},{"output_type":"execute_result","data":{"text/plain":"{'input': 'For every of the following headlines, extract the company name and whether the financial sentiment is positive, neutral or negative. \\nLoad this data into a pandas dataframe. \\nThe dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \\nThe dataframe can then be saved in the current working directory under the name financial_analysis.csv.\\nIf a csv file already exists with the same name, it should be overwritten.\\n\\nThe headlines are the following:\\n[\"Finnish Aktia Group \\'s operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", \\'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\\', \\'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\\', \\'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\\', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries \\' ( SFI ) pulp mill in Sabah , Malaysia .\", \\'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .\\']',\n 'output': 'The dataframe with the extracted company names, financial sentiment, and headlines has been saved as a csv file in the current working directory under the name financial_analysis.csv.'}"},"metadata":{},"execution_count":17}]},{"source":"Observe the output above. Do you see anything that could be improved? We will come back to this later in this notebook.\n\nFor now, let's quickly load our `.csv` file in a dataframe to analyze.","metadata":{},"id":"f4865a0e-2caf-4242-802f-1553ba1d3b5d","cell_type":"markdown"},{"source":"### Instructions\n\nLoad the data in a dataframe for evaluation.\n- Import `pandas` under its usual alias: `pd`.\n- Load the `financial_analysis.csv` file into a dataframe. Assign to `df`.\n- Print the dataframe. As our dataframe only contains six rows, we can just print the entire dataframe.","metadata":{},"id":"86270b08-e124-43bb-8834-210bdb6c0a43","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\nUse the `pd.read_csv(filename)` function to load the `.csv` file to dataframe.\n\n</p>\n</details>","metadata":{},"id":"de02653d-dda5-432a-ba2b-16f5faf0686e","cell_type":"markdown"},{"source":"# Make the necessary import.\nimport pandas as pd\n\n# Load the CSV file into a dataframe.\nfin_df= pd.read_csv('financial_analysis.csv')\n\n# Print the dataframe.\nprint(fin_df)","metadata":{"executionCancelledAt":null,"executionTime":46,"lastExecutedAt":1747336028162,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Make the necessary import.\nimport pandas as pd\n\n# Load the CSV file into a dataframe.\nfin_df= pd.read_csv('financial_analysis.csv')\n\n# Print the dataframe.\nprint(fin_df)","outputsMetadata":{"0":{"height":206,"type":"stream"}}},"id":"e1c01e13-0d39-407d-80f6-f0ebe5f76827","cell_type":"code","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":"  Company Name  ...                                           Headline\n0      Finnish  ...  Finnish Aktia Group 's operating profit rose t...\n1      Finnish  ...  Finnish measuring equipment maker Vaisala Oyj ...\n2      Finnish  ...  Finnish pharmaceuticals company Orion reports ...\n3      Finnish  ...  Tiimari , the Finnish retailer , reported to h...\n4      Finnish  ...  Finnish Metso Paper has been awarded a contrac...\n5      Finnish  ...  Finnish Outokumpu Technology has been awarded ...\n\n[6 rows x 3 columns]\n"}]},{"source":"When analyzing the output above (looking at the company names and sentiment), you will probably notice some room for improvement. \n\nCompany names and sentiment may not be extracted in a very powerful way. The reason for this is that without further instructions, the GPT-model will use the PythonREPLTool (Python code) to complete its task. Looking back at the output from our last call to the Python agent, we may find that it created rule sets on how to extract the company name or determine the sentiment. These hard-coded rules negate the power of large language models! We will improve on this in Task 7.\n\nAnother problem that might arise is that the *sentiment* of a sentence can differ from *financial sentiment*. For example, an aggressive headline complaining about a large corporation making too much profit might result in negative sentiment, while from a financial analysis point of view the sentiment is positive. To steer the GPT-model to our desired outcome, we will now introduce few shot learning.\n\nFor example, *Company X was awarded a new contract* might be categorized as a neutral sentence. The sentence itself is simply an objective statement or observation. Nothing is mentioned about whether we like or dislike that particular company because of this. From a financial perspective however, this is considered as something positive. To steer the GPT-model to our desired outcome, we will now introduce few shot learning.","metadata":{},"id":"d37d368b-b177-41f9-abe8-dacf99486401","cell_type":"markdown"},{"source":"## Task 6: Adding Few Shot Learning","metadata":{},"id":"31bb73ca-089b-4bdf-ba9f-e2efbe3174f0","cell_type":"markdown"},{"source":"Few shot learning basically comes down to adding some examples into our prompt, in this case, what we consider to be positive or negative headlines. A shot refers to an example given to the model in the input prompt (or sometimes the system message).\n\nWe distinguish three categories of contextual learning:\n- Few shot leaning (multiple examples)\n- Single shot learning (one example)\n- Zero shot leaning (no examples)\n\nFew shot learning might take more effort in terms of prompt building, but it will generally yield better results, as the model has a better understanding of our desired outcome.\n\nLet's look at an example of financial sentiment analysis without few shot learning first.","metadata":{},"id":"cbe98ba4-9d30-40e7-8a80-d8b780a48105","cell_type":"markdown"},{"source":"### Instructions\n\nCreate a prompt template with output parsing to determine the financial sentiment of all headlines.\n- Create a new `PromptTemplate` called `sentiment_template`. Remember the three arguments `template`, `input_variables` and `partial_variables`. Assign to `sentiment_template`.\n    - We can reuse the `format_instructions` variable that we have loaded into memory before.\n    - As a template, use: \n```\n\"Get the financial sentiment of each of the following headlines. The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\"\n```\n\n\n- Format the template on all headlines. Assign to `formatted_sentiment_template`.\n- Run the formatted template by invoking our `model` and assign the result to our temporary variable `_output`.\n- Parse the output using the output parser. Assign the result to `sentiments`.\n- Print the sentiments.","metadata":{},"id":"59658d1d-3b7c-4e7c-8521-c295982c3de7","cell_type":"markdown"},{"source":"# Create a new prompt template with output parsing.\nsentiment_template= PromptTemplate(\n    template=\"Get the financial sentiment of each of the following headlines. The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\",\n    input_variables=['headlines'],\n    partial_variables={\"format_instructions\":format_instructions}    \n)\n\n# Format the prompt template.\nformat_sentiment_template= sentiment_template.format(headlines=headlines)\n\n# Invoke the model on the formatted prompt template.\n_output=model.invoke(format_sentiment_template)\n\n# Parse the output.\nsentiments=output_parser.parse(_output)\n\n# Print the list of sentiments.\nsentiments","metadata":{"executionCancelledAt":null,"executionTime":968,"lastExecutedAt":1747336029130,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a new prompt template with output parsing.\nsentiment_template= PromptTemplate(\n    template=\"Get the financial sentiment of each of the following headlines. The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\",\n    input_variables=['headlines'],\n    partial_variables={\"format_instructions\":format_instructions}    \n)\n\n# Format the prompt template.\nformat_sentiment_template= sentiment_template.format(headlines=headlines)\n\n# Invoke the model on the formatted prompt template.\n_output=model.invoke(format_sentiment_template)\n\n# Parse the output.\nsentiments=output_parser.parse(_output)\n\n# Print the list of sentiments.\nsentiments"},"id":"30dc1956-488a-4c93-a887-a5ea803f30a4","cell_type":"code","execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":"['Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive']"},"metadata":{},"execution_count":19}]},{"source":"It is hard to evaluate the sentiments without seeing the associated headline. To make our lives easier, let's write a quick function to easily visualize and interpret the result.","metadata":{},"id":"843f4c4d-8185-4ebe-991b-1d179cc5e15a","cell_type":"markdown"},{"source":"### Instructions\n\nVisualize and interpret the results of the sentiment analysis.\n- Write a function called `visualize_sentiments` to visualize both the sentiment and associated headline, for all headlines. \n    - The input for this function should be two lists: one containing all headlines and one containing all sentiments.\n    - As a best practice, start with using an `assert` that ensures that both lists are of equal length.\n    - There are many ways to create this: simply printing with f-strings, making a dictionary or Dataframe, get creative!\n- Call the `visualize_sentiments` function using `headlines` and `sentiments` as input.","metadata":{},"id":"da3d6834-6c1e-4542-80f3-dc1b385f6477","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\n- We can assert that both input lists are of equal length by using `assert len(list1) == len(list2)`.\n- A very simplistic way of visualizing the sentiments per headline is using f-strings, such as `f\"{sentiments[i]}: {headlines[i]}\"` in a loop. \n\n</p>\n</details>","metadata":{},"id":"5bf24583-5de7-45fb-849b-16db6d86b724","cell_type":"markdown"},{"source":"# Define a new function with two inputs\ndef visualize_sentiments(headlines,sentiments):\n    # Assert that both inputs are of equal length\n    assert len(headlines)==len(sentiments)\n\n    # Visualize the sentiments and their respective headlines\n    for i,_ in enumerate(headlines):\n        print(f\"{sentiments[i].upper()}:{headlines[i]}\")\n\n# Call the function\nvisualize_sentiments(headlines, sentiments)","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1747336029178,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define a new function with two inputs\ndef visualize_sentiments(headlines,sentiments):\n    # Assert that both inputs are of equal length\n    assert len(headlines)==len(sentiments)\n\n    # Visualize the sentiments and their respective headlines\n    for i,_ in enumerate(headlines):\n        print(f\"{sentiments[i].upper()}:{headlines[i]}\")\n\n# Call the function\nvisualize_sentiments(headlines, sentiments)","outputsMetadata":{"0":{"height":332,"type":"stream"}}},"id":"4e7ca1a7-4249-4826-ac57-5093ee3de9d1","cell_type":"code","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":"POSITIVE:Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\nNEGATIVE:Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\nPOSITIVE:Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\nPOSITIVE:Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\nPOSITIVE:Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\nPOSITIVE:Finnish Outokumpu Technology has been awarded several new grinding technology contracts .\n"}]},{"source":"Now we might see that the financial sentiment is not always correctly assigned, such as a contract being awarded not being recognized as a financially positive headline.\nTo improve the performance, we will add some examples. Few shot learning can be done by either giving some observations (headlines in this case) accompanied by their ground truth (label) *or* by giving an abstract description of what is seen as positive, negative or neutral.\n\nIn this case, we will opt for the later. Here is a prompt you can use for few shot learning:\n\n```\n\"\"\"\nIf a company is doing financially better than before, the sentiment is positive. For example, when profits or revenue have increased since the last quarter or year, exceeding expectations, a contract is awarded or an acquisition is announced.\nIf the company's profits are decreasing, losses are mounting up or overall performance is not meeting expectations, the sentiment is negative.\nIf nothing positive or negative is mentioned from a financial perspective, the sentiment is neutral.\n\"\"\"\n```","metadata":{},"id":"3bc7af8c-461c-42d2-ae37-2da14438c5c6","cell_type":"markdown"},{"source":"### Instructions\n\nCreate and run a prompt template using few shot learning.\n- Store the prompt above in a variable called `sentiment_examples`.\n- Create a `PromptTemplate` called `sentiment_template` like we did two cells above.\n    - In our template, we will add a new input variable called `few_shot_examples`. This can be placed in between the two sentences.\n    - Don't forget to add our new input variables to the list of `input_variables`.\n    - Reuse the same `format_instructions` as before.\n- Format the `sentiment_template`. Remember that you will need to pass both `headlines` and `sentiment_examples`.\n- Run the formatted template by invoking our `model` and assign the result to our temporary variable `_output`.\n- Parse the output using the output parser. Assign the result to `sentiments`.\n- Visualize and interpret the results using your newly created `visualize_sentiments` function.","metadata":{},"id":"3142596a-b723-4d4f-9d2d-2066531aeea6","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\nThe `template` we should use could look like this: \n\n```\n\"Get the financial sentiment of each of the following headlines. {few_shot_examples} The output is strictly limited to [`Positive`, `Negative`, `Neutral`]: {headlines}.\\n{format_instructions}\"\n```\n\nWhen formatting the template, we can pass along `sentiment_examples` to the `few_shot_examples` input variable.\n    \n</p>\n</details>","metadata":{},"id":"7364ebe9-17a1-4888-844c-89efeb3b1c9b","cell_type":"markdown"},{"source":"# Store the few shot examples in a variable.\nsentiment_examples = \"\"\"\nIf a company is doing financially better than before, the sentiment is positive. For example, when profits or revenue have increased since the last quarter or year, exceeding expectations, a contract is awarded or an acquisition is announced.\nIf the company's profits are decreasing, losses are mounting up or overall performance is not meeting expectations, the sentiment is negative.\nIf nothing positive or negative is mentioned from a financial perspective, the sentiment is neutral.\n\"\"\"\n# Instantiate a new prompt template with the format instructions.\nsentiment_template= PromptTemplate(\n    template= \"Get the financial sentiment of each of the following headlines. {few_shot_examples} The output is strictly limited to [`Positive`, `Negative`, `Neutral`]: {headlines}.\\n{format_instructions}\",\n    input_variables = [\"headlines\",\"few_shot_examples\"],\n    partial_variables={\"format_instructions\":format_instructions}\n\n)\n\n# Format the template.\nf_sentiment_template = sentiment_template.format(headlines=headlines,few_shot_examples = sentiment_examples)\n\n# Invoke the model on the formatted template.\n_output=model.invoke(f_sentiment_template)\n\n# Parse the model output.\nsentiments= output_parser.parse(_output)\n\n# Visualize the result.\nvisualize_sentiments(headlines,sentiments)","metadata":{"executionCancelledAt":null,"executionTime":726,"lastExecutedAt":1747336029904,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Store the few shot examples in a variable.\nsentiment_examples = \"\"\"\nIf a company is doing financially better than before, the sentiment is positive. For example, when profits or revenue have increased since the last quarter or year, exceeding expectations, a contract is awarded or an acquisition is announced.\nIf the company's profits are decreasing, losses are mounting up or overall performance is not meeting expectations, the sentiment is negative.\nIf nothing positive or negative is mentioned from a financial perspective, the sentiment is neutral.\n\"\"\"\n# Instantiate a new prompt template with the format instructions.\nsentiment_template= PromptTemplate(\n    template= \"Get the financial sentiment of each of the following headlines. {few_shot_examples} The output is strictly limited to [`Positive`, `Negative`, `Neutral`]: {headlines}.\\n{format_instructions}\",\n    input_variables = [\"headlines\",\"few_shot_examples\"],\n    partial_variables={\"format_instructions\":format_instructions}\n\n)\n\n# Format the template.\nf_sentiment_template = sentiment_template.format(headlines=headlines,few_shot_examples = sentiment_examples)\n\n# Invoke the model on the formatted template.\n_output=model.invoke(f_sentiment_template)\n\n# Parse the model output.\nsentiments= output_parser.parse(_output)\n\n# Visualize the result.\nvisualize_sentiments(headlines,sentiments)","outputsMetadata":{"0":{"height":332,"type":"stream"}}},"id":"78e963c2-d4a5-409b-b4b7-7a1d30a13346","cell_type":"code","execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":"POSITIVE:Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\nNEGATIVE:Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\nPOSITIVE:Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\nPOSITIVE:Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\nPOSITIVE:Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\nPOSITIVE:Finnish Outokumpu Technology has been awarded several new grinding technology contracts .\n"}]},{"source":"## Task 7: Combining Tools and Output Parsing","metadata":{},"id":"300e7f24-e934-4c49-a710-c67cb3413693","cell_type":"markdown"},{"source":"As you may have noticed in Task 5, using tools is not a guaranteed success. We can improve the performance by clearly determining which tasks can be completed by the Python tool and which we use the GPT-model itself for.\nTo maximize the powerful capabilities of the GPT-model, we prefer its use over hard-coded rule sets when it comes to company name extraction or financial sentiment analysis.\nHowever, other (cumbersome) tasks that do not require the ability to handle ambiguity, are often best left to the Python tool.\n\nLet's ask the model to use the existing lists that we got from our templates (`company_names` and `sentiments`), but use the Python tool to neatly place them in a Pandas dataframe and write them locally to a `.csv` file.\n\nUse the following prompt:\n\n```\nf\"\"\"Create a dataframe with two columns: company_name, sentiment and headline.\n                   To fill the dataframe, use the following lists respectively: {str(company_names)}, {str(sentiments)} and {str(headlines)}. \n                   The dataframe can then be saved in the current working directory under the name financial_analysis_with_parsing.csv.\n                   If a csv file already exists with the same name, it should be overwritten.\n                   \"\"\"\n```\n\nIn the prompt above, we pass along lists that were generated by the GPT-model before (when it did not have access to the Python tool). Now we only want to give instructions on tasks that should be carried out using Python code, such as the creation of the dataframe, saving (and overwriting) it, ...\n\nKeep in mind that we can use this same way of working for much more complex tasks, that might encompass extensive coding requirements.","metadata":{},"id":"4e447e81-3b31-4e74-a567-53623cc863ce","cell_type":"markdown"},{"source":"### Instructions\n\n- Invoke the `agent_executor` on the prompt above.","metadata":{},"id":"d690b3d5-2602-4c3b-990f-85990d4e301d","cell_type":"markdown"},{"source":"# Invoke the agent to create a file with the headlines, company names and sentiments.\nagent_executor.invoke(f\"\"\"Create a dataframe with two columns: company_name, sentiment and headline.\n                   To fill the dataframe, use the following lists respectively: {str(company_names)}, {str(sentiments)} and {str(headlines)}. \n                   The dataframe can then be saved in the current working directory under the name financial_analysis_with_parsing.csv.\n                   If a csv file already exists with the same name, it should be overwritten.\n                   \"\"\")","metadata":{"executionCancelledAt":null,"executionTime":7403,"lastExecutedAt":1747337409015,"lastExecutedByKernel":"43973903-38bf-4cf5-966e-d6bc8437f468","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Invoke the agent to create a file with the headlines, company names and sentiments.\nagent_executor.invoke(f\"\"\"Create a dataframe with two columns: company_name, sentiment and headline.\n                   To fill the dataframe, use the following lists respectively: {str(company_names)}, {str(sentiments)} and {str(headlines)}. \n                   The dataframe can then be saved in the current working directory under the name financial_analysis_with_parsing.csv.\n                   If a csv file already exists with the same name, it should be overwritten.\n                   \"\"\")","outputsMetadata":{"0":{"height":613,"type":"stream"}}},"id":"188e0ab4-1515-49a2-a8db-09582ec5be21","cell_type":"code","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m I need to import pandas to create a dataframe. I also need to create the lists for the columns and the data.\nAction: Python_REPL\nAction Input: import pandas as pd\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m Now that I have imported pandas, I can create the dataframe using the lists.\nAction: Python_REPL\nAction Input: df = pd.DataFrame({'company_name': ['Aktia Group', 'Vaisala Oyj', 'Orion', 'Tiimari', 'Metso Paper', 'Outokumpu Technology'], 'sentiment': ['Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive'], 'headline': [\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .', 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .', 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\", 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']})\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m Now that I have created the dataframe, I need to save it in the current working directory.\nAction: Python_REPL\nAction Input: df.to_csv('financial_analysis_with_parsing.csv', index=False)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I now know the final answer.\nFinal Answer: The dataframe has been saved in the current working directory under the name financial_analysis_with_parsing.csv.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"},{"output_type":"execute_result","data":{"text/plain":"{'input': 'Create a dataframe with two columns: company_name, sentiment and headline.\\n                   To fill the dataframe, use the following lists respectively: [\\'Aktia Group\\', \\'Vaisala Oyj\\', \\'Orion\\', \\'Tiimari\\', \\'Metso Paper\\', \\'Outokumpu Technology\\'], [\\'Positive\\', \\'Negative\\', \\'Positive\\', \\'Positive\\', \\'Positive\\', \\'Positive\\'] and [\"Finnish Aktia Group \\'s operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", \\'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\\', \\'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\\', \\'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\\', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries \\' ( SFI ) pulp mill in Sabah , Malaysia .\", \\'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .\\']. \\n                   The dataframe can then be saved in the current working directory under the name financial_analysis_with_parsing.csv.\\n                   If a csv file already exists with the same name, it should be overwritten.\\n                   ',\n 'output': 'The dataframe has been saved in the current working directory under the name financial_analysis_with_parsing.csv.'}"},"metadata":{},"execution_count":27}]},{"source":"If we look at our working directory, we will see a new file pop up, called `financial_analysis_with_parsing.csv`.\n\nLet's analyze it and compare against the output from Task 5.","metadata":{},"id":"477b7d8a-2e4e-4f74-8dc1-b538fcd09f23","cell_type":"markdown"},{"source":"### Instructions\n\nLoad and display the new file.\n- Load `financial_analysis_with_parsing.csv` into a dataframe called `df`.\n- Print the dataframe.","metadata":{},"id":"9ed9c0b7-f961-493e-8a38-7143050448f8","cell_type":"markdown"},{"source":"# Load the CSV file into a dataframe.\ndf=pd.read_csv('financial_analysis_with_parsing.csv')\n\n# Print the dataframe.\nprint(df)","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":206,"type":"stream"}}},"id":"142e344b-16c6-46fa-996f-3c1da9b52956","cell_type":"code","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":"           company_name  ...                                           headline\n0           Aktia Group  ...  Finnish Aktia Group 's operating profit rose t...\n1           Vaisala Oyj  ...  Finnish measuring equipment maker Vaisala Oyj ...\n2                 Orion  ...  Finnish pharmaceuticals company Orion reports ...\n3               Tiimari  ...  Tiimari , the Finnish retailer , reported to h...\n4           Metso Paper  ...  Finnish Metso Paper has been awarded a contrac...\n5  Outokumpu Technology  ...  Finnish Outokumpu Technology has been awarded ...\n\n[6 rows x 3 columns]\n"}]},{"source":"## Task 8: Using the OpenAI Moderation API","metadata":{},"id":"50ca52ca-41f3-4aea-bd0a-4862a9465a7a","cell_type":"markdown"},{"source":"The OpenAI API platform also sports a Moderation API, in addition to their model and embeddings APIs. The Moderation API can check whether the prompt contains explicit content and can flag various categories like hate, violence, sexually explicit content and so on. When we are building an application targeting large user bases, it becomes crucial to leverage the Moderation API and filter our input prompts to avoid the complications associated with unethical LLM usage.\n\nTo test the Moderation API, we have a small sample of five comments picked from the `r/WallStreetBets` subreddit, stored in the `reddit_comments.txt` file.\n\nLet's start by reading the text file.","metadata":{},"id":"27cd50c5-43a2-4082-8dde-d92c183d38cd","cell_type":"markdown"},{"source":"### Content warning\n\nIn order to trigger the moderation API, the comments were specifically chosen to be offensive. If you are sensitive to awful content, you may wish to avoid printing and reading the text.\n\nNaturally, neither the project instructor nor DataCamp agrees with the ideas expressed within this text file.","metadata":{},"id":"b05cfef2-ba53-4372-a6f3-c998f1d25164","cell_type":"markdown"},{"source":"### Instructions\n\nRead the text file and store its lines in a variable called `comments`.\n- Open `reddit_comments.txt` as read.\n- Use the `.readlines()` method to store its contents in a list called `comments`.\n- Optionally print the comments.","metadata":{},"id":"4e66ebca-010f-4189-b2fd-3a33ec0b378d","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\nHere we can use the same `with open(filename, \"r\") as file:` structure as in Task 1.\n\n</p>\n</details>","metadata":{},"id":"7772dd1f-97c0-4713-8836-e06c859b905f","cell_type":"markdown"},{"source":"# Load the lines of the text file.\nwith open('reddit_comments.txt',\"r\")as file:\n    comments=file.readlines()\n\n# Optionally print the comments.\n# comments\nprint(comments)","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"lastExecutedByKernel":null,"outputsMetadata":{"0":{"height":437,"type":"stream"}}},"id":"a5a029ff-5387-49f7-8a77-e3cdd40e7282","cell_type":"code","execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":"[\"It's the poors fault for thinking they had a chance in a negative sum gambling casino run by people richer than you who hired Asian quants that are smarter than you.\\n\", \"Canada is basically a global real estate investment scheme. It's not even a country, it's a showroom.\\n\", 'Lol China not going to make a dent in the global scale. Wake me up when America’s housing market is about to implode that’s when I’m pulling out all my investments. Because the world is going to burn.\\n', 'I would normally have the knee-jerk reaction to seethe at this post but I remind myself that if I had a lot of money I would probably be the snobbiest and stingiest rich person ever. I wouldn’t even help anyone even if they begged me to financially free them from their Wendy’s dumpster obligations\\n', \"I know China will be fine because Peter Zeihan keeps saying China is imploding. If you want to know what the US State Department desperately wants you to believe, just keep up to date with whatever Peter Zeihan is saying. The dude somehow made a career about being wrong about everything all the time and always blindsided by new developments. 3 months ago he's doing vblogs about how China is completely cut off from semiconductors and the immensely complicated tech necessary to catch up - and then last week it's revealed China has beaten USA to producing 7nm chips domestically. Literally just 3 months ago Zeihan and everyone educated by Western news sources thought China would be stuck at 28nm for years to come. If the rumours circulating of China developing SSMB EUV are true then it's truly game over, China's won\"]\n"}]},{"source":"### Instructions\n\nAnalyze a comment using the Moderation API.\n- Pick a comment from the dataset (using and index between 0 - 4) and store this in a variable called `comment`.\n- Use the `openai` package to define an OpenAI model. Assign to `client`.\n- Use the API by calling the previously defined `client`'s `.moderations.create()` method. For the `input` argument, pass the `comment`. Assign to `moderation_output`.\n- Print the comment and moderation output.","metadata":{},"id":"e3b3e694-2176-4d46-91a2-7c17ef31b980","cell_type":"markdown"},{"source":"# Pick a comment.\ncomment=comments[0]\n\n# Define an OpenAI model. Assign to client.\n\nclient=openai.OpenAI()\n# Send the comment to the Moderation API. Assign to moderation_output.\nmoderation_output=client.moderations.create(input=comment)\n\n# Optionally print the comment.\nprint(comment)\n\n# Print the output.\nmoderation_output","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":80,"type":"stream"}}},"id":"306b2862-bcdb-4e67-add4-c776ddc14c5f","cell_type":"code","execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":"It's the poors fault for thinking they had a chance in a negative sum gambling casino run by people richer than you who hired Asian quants that are smarter than you.\n\n"},{"output_type":"execute_result","data":{"text/plain":"ModerationCreateResponse(id='modr-BXYkldRQWAC7a8SHhfBSJmOPWB1dc', model='text-moderation-007', results=[Moderation(categories=Categories(harassment=True, harassment_threatening=False, hate=False, hate_threatening=False, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_scores=CategoryScores(harassment=0.9698618650436401, harassment_threatening=5.613575194729492e-05, hate=0.2271779626607895, hate_threatening=1.5068104630699963e-07, self_harm=8.873935541942046e-08, self_harm_instructions=1.5018551380308054e-07, self_harm_intent=1.9745028723150426e-08, sexual=8.637963219371159e-06, sexual_minors=2.2542182875895378e-07, violence=0.00021484204626176506, violence_graphic=3.945473565636348e-07, self-harm=8.873935541942046e-08, sexual/minors=2.2542182875895378e-07, hate/threatening=1.5068104630699963e-07, violence/graphic=3.945473565636348e-07, self-harm/intent=1.9745028723150426e-08, self-harm/instructions=1.5018551380308054e-07, harassment/threatening=5.613575194729492e-05), flagged=True)])"},"metadata":{},"execution_count":33}]},{"source":"We can analyze the output above to determine whether the comment has been deemed explicit or not. The `\"flagged\"` boolean will show us if any (at least one) category has been flagged, and underneath we can see which categories have been flagged.","metadata":{},"id":"1ec05e3a-144a-4abd-8a1c-02b72e2cb41f","cell_type":"markdown"},{"source":"The moderation scores for each category can be retrieved to explore why the text was flagged as inappropriate. It's slightly tedious code, but can be reused exactly whenever you use the moderation API.","metadata":{},"id":"9fa1e045-3679-4d6b-b97d-e7bf27bd5a83","cell_type":"markdown"},{"source":"# Run this code to see the scores\npd.DataFrame(moderation_output.results[0].dict())[[\"categories\", \"category_scores\"]]","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"80bc2a84-bf34-440f-91b3-b630936a7a20","nodeType":"const"}}}}},"id":"8271e107-d1da-4a84-8557-e163f7a1f103","cell_type":"code","execution_count":34,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"string"},{"name":"categories","type":"boolean"},{"name":"category_scores","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":["harassment","harassment_threatening","hate","hate_threatening","self_harm","self_harm_instructions","self_harm_intent","sexual","sexual_minors","violence","violence_graphic","self-harm","sexual/minors","hate/threatening","violence/graphic","self-harm/intent","self-harm/instructions","harassment/threatening"],"categories":[true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false],"category_scores":[0.969861865,0.0000561358,0.2271779627,1.507e-7,8.87e-8,1.502e-7,1.97e-8,0.000008638,2.254e-7,0.000214842,3.945e-7,8.87e-8,2.254e-7,1.507e-7,3.945e-7,1.97e-8,1.502e-7,0.0000561358]}},"total_rows":18,"truncation_type":null},"text/plain":"                        categories  category_scores\nharassment                    True     9.698619e-01\nharassment_threatening       False     5.613575e-05\nhate                         False     2.271780e-01\nhate_threatening             False     1.506810e-07\nself_harm                    False     8.873936e-08\nself_harm_instructions       False     1.501855e-07\nself_harm_intent             False     1.974503e-08\nsexual                       False     8.637963e-06\nsexual_minors                False     2.254218e-07\nviolence                     False     2.148420e-04\nviolence_graphic             False     3.945474e-07\nself-harm                    False     8.873936e-08\nsexual/minors                False     2.254218e-07\nhate/threatening             False     1.506810e-07\nviolence/graphic             False     3.945474e-07\nself-harm/intent             False     1.974503e-08\nself-harm/instructions       False     1.501855e-07\nharassment/threatening       False     5.613575e-05","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>categories</th>\n      <th>category_scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>harassment</th>\n      <td>True</td>\n      <td>9.698619e-01</td>\n    </tr>\n    <tr>\n      <th>harassment_threatening</th>\n      <td>False</td>\n      <td>5.613575e-05</td>\n    </tr>\n    <tr>\n      <th>hate</th>\n      <td>False</td>\n      <td>2.271780e-01</td>\n    </tr>\n    <tr>\n      <th>hate_threatening</th>\n      <td>False</td>\n      <td>1.506810e-07</td>\n    </tr>\n    <tr>\n      <th>self_harm</th>\n      <td>False</td>\n      <td>8.873936e-08</td>\n    </tr>\n    <tr>\n      <th>self_harm_instructions</th>\n      <td>False</td>\n      <td>1.501855e-07</td>\n    </tr>\n    <tr>\n      <th>self_harm_intent</th>\n      <td>False</td>\n      <td>1.974503e-08</td>\n    </tr>\n    <tr>\n      <th>sexual</th>\n      <td>False</td>\n      <td>8.637963e-06</td>\n    </tr>\n    <tr>\n      <th>sexual_minors</th>\n      <td>False</td>\n      <td>2.254218e-07</td>\n    </tr>\n    <tr>\n      <th>violence</th>\n      <td>False</td>\n      <td>2.148420e-04</td>\n    </tr>\n    <tr>\n      <th>violence_graphic</th>\n      <td>False</td>\n      <td>3.945474e-07</td>\n    </tr>\n    <tr>\n      <th>self-harm</th>\n      <td>False</td>\n      <td>8.873936e-08</td>\n    </tr>\n    <tr>\n      <th>sexual/minors</th>\n      <td>False</td>\n      <td>2.254218e-07</td>\n    </tr>\n    <tr>\n      <th>hate/threatening</th>\n      <td>False</td>\n      <td>1.506810e-07</td>\n    </tr>\n    <tr>\n      <th>violence/graphic</th>\n      <td>False</td>\n      <td>3.945474e-07</td>\n    </tr>\n    <tr>\n      <th>self-harm/intent</th>\n      <td>False</td>\n      <td>1.974503e-08</td>\n    </tr>\n    <tr>\n      <th>self-harm/instructions</th>\n      <td>False</td>\n      <td>1.501855e-07</td>\n    </tr>\n    <tr>\n      <th>harassment/threatening</th>\n      <td>False</td>\n      <td>5.613575e-05</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":34}]},{"source":"## Summary","metadata":{},"id":"b81d3a0b-b9ac-4def-b19a-b501a42d9ff2","cell_type":"markdown"},{"source":"Congratulations on completing this module! You should be able to get started with basic LangChain projects yourself now. \n\nYou've learned:\n- Important prompt engineering tricks and optimizations\n- Setting up prompt templates\n- Using LLMChains\n- Using LangChain output parsing to generate Python objects to be used downstream\n- Using LangChain Agents and Tools to add additional functionalities to generative AI projects\n- Leveraging the Moderation API to act as a filter of user input\n\nWe wish you the best of luck in the following modules!","metadata":{},"id":"6c9ba593-30fa-43b5-9b18-2bd6c7e4087e","cell_type":"markdown"}],"metadata":{"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}